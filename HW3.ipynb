{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 3 Optimization (80pts)\n",
    "\n",
    "**Due 11:59pm, Apr 29th.**\n",
    "\n",
    "## Please restart the kernel and run all before you submit !\n",
    "\n",
    "\n",
    "## Your Name: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: SGD with arbitrary batch size  (50pts)\n",
    "\n",
    "**The goal of this exercise is to implement SGD with arbitrary batch size for a certain linear regression model.** \n",
    "\n",
    "Given data points $(x^i,y^i)_{i=1}^m$ where each data point $x$ has three features/attributes, i.e. $x=(x_1,x_2,x_3)$, we consider the following linear regression model\n",
    "$$ y =  a_0 + a_1x_1 + a_2x_2 + a_3x_3.$$\n",
    "\n",
    "Here, $a_0,a_1,a_2,a_3$ are coefficients. \n",
    "\n",
    "The corresponding optimization problem is \n",
    "\n",
    "$$ \\mathop{\\mathrm{Loss}}(a_0,a_1,a_2,a_3) = \\frac{1}{m}\\sum_{i=1}^{m} (a_0+a_1x_1^i+a_2x_2^i+a_3x_3^i-y^i)^2 $$\n",
    "\n",
    "\n",
    "You should do the following three things:\n",
    "\n",
    "1. Write a python function to implement SGD with arbitrary batch_size. Hint: you can write it as a python function and treat batch size as a function input.\n",
    "\n",
    "2. Select at least 4 batch sizes and fix number of iteration, then run SGD for different stepsize, report the the running time for each batch size (use `print`). What is your conclusion?\n",
    "\n",
    "3. Use the same batch sizes as part 2, then draw a plot to visualize the the loss after each iteration vs iterations. What is your conclusion?\n",
    "\n",
    "Requirements:\n",
    "\n",
    "1. Your SGD algorithm should allow different batch size. \n",
    "\n",
    "2. Write python functions to do 2 and 3.\n",
    "\n",
    "3. Detailed docustring is required for each function. Add necessary inline comments and markdown to explain your code or make comments.\n",
    "\n",
    "Grading is based on the codes (15 pts), function docstrings (10 pts), comments (10 pts) and conclusions (15 pts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell to generate data points\n",
    "m = 1000                                # number of data points\n",
    "n = 3                                   # number of features\n",
    "x = np.random.randn(m,n)                # each row of x represents a data point\n",
    "theta = np.random.randn(n,1)            # true coefficients a_1, a_2, a_3\n",
    "y = x@theta + 3 + np.random.rand(m,1)   # observations and true a_0 = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your explanation on the relation between batch size and number of iterations. (please change this cell to markdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: SGD animation for polynomial regression (30 pts)\n",
    "\n",
    "In this exercise, our goal is to create a similar animation (which is available [here](https://nbviewer.org/github/PhilChodrow/PIC16B/blob/master/lectures/math/optimization.ipynb)) for polynomial regression model.  \n",
    "\n",
    "\n",
    "#### Comments:\n",
    "You cannot copy the code in the link directly because \n",
    "\n",
    "1. the sample code is for simple linear regression only, but we are considering polynomial regression.\n",
    "\n",
    "2. the data generating process is included in the class initialization, however training data are provided in this exercise.\n",
    "\n",
    "Please understand the sample code first, and then modify it accordingly. It is also fine if you do not write a class (class is used in the sample code) to do the animation.\n",
    "\n",
    "#### Grading policy:\n",
    "1. There is no error in your code.\n",
    "2. The animation result looks reasonable.\n",
    "3. Docstring and comments are required for your code.\n",
    "\n",
    "\n",
    "#### Mathematics on polynomial regression:\n",
    "Given data points $(x_i,y_i)_{i=1}^m$, polynomial regression is considered if we believe that the true relation between input $x$ and output $y$ can be described by a polynomial $y=a_0+a_1x+\\cdots+a_nx^n$ for some degree $n$.\n",
    "\n",
    "The goal is to find coefficients $a_0,\\cdots,a_n$ by minimizing the loss function\n",
    "$$ \\mathop{\\mathrm{minimize}}_{a_o,\\cdots,a_n} \\frac{1}{m}\\sum_{i=1}^m (a_0+a_1x_i+\\cdots+a_nx_i^n-y_i)^2 $$\n",
    "\n",
    "Then we can use SGD to solve this optimization problem.\n",
    "\n",
    "#### Data Generation\n",
    "\n",
    "Please run the following code to generate the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# number of observations\n",
    "m = 100\n",
    "# generate input x \n",
    "X = np.random.uniform(0,3,m)\n",
    "X.sort()\n",
    "# generate output y\n",
    "y = -2 - 2*X + X**2 + 0.1*np.random.randn(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
