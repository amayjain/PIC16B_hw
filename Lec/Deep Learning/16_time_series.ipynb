{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Data\n",
    "\n",
    "In this lecture, we will discuss recurrent neural network which works for time series data.\n",
    "\n",
    "Time Series Data: Each data point in a time series is linked to a timestamp, which shows the exact time when the data was observed or recorded. Many fields, including finance, economics, weather forecasting, and machine learning, frequently employ this kind of data.\n",
    "\n",
    "When we consider the previous structures, we implicitly assume that samples are realizations of some unknown distribution and are **independent**. However, time series data are dependent because of timestamp.\n",
    "\n",
    "The fact that time series data frequently display patterns or trends across time, such as seasonality or cyclical patterns, is an essential feature associated with it. To make predictions or learn more about the underlying processes or occurrences being observed, these patterns can be analyzed and modeled.\n",
    "\n",
    "Recurrent Neural Networks (RNN) model the temporal dependencies present in the data as it contains an implicit memory of previous inputs. Hence, time series data being sequential in nature is often used in RNN. For working with time series data in RNNs, TensorFlow provides a number of APIs and tools, like tf.keras.layers.RNN API, which allows to create of unique RNN cell classes and use them with data. Several RNN cell types are also supported by this API, including Basic RNN, LSTM, and GRU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-03 14:04:25.098954: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to install yfinance packages, type pip install yfinance should work. Then, please restart your kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.40-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /opt/anaconda3/lib/python3.8/site-packages (from yfinance) (1.5.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/anaconda3/lib/python3.8/site-packages (from yfinance) (1.24.3)\n",
      "Requirement already satisfied: requests>=2.31 in /opt/anaconda3/lib/python3.8/site-packages (from yfinance) (2.31.0)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /opt/anaconda3/lib/python3.8/site-packages (from yfinance) (4.9.3)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /opt/anaconda3/lib/python3.8/site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /opt/anaconda3/lib/python3.8/site-packages (from yfinance) (2023.3.post1)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Downloading frozendict-2.4.4.tar.gz (315 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.9/315.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.17.5.tar.gz (3.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.11.1 in /opt/anaconda3/lib/python3.8/site-packages (from yfinance) (4.12.2)\n",
      "Requirement already satisfied: html5lib>=1.1 in /opt/anaconda3/lib/python3.8/site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in /opt/anaconda3/lib/python3.8/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /opt/anaconda3/lib/python3.8/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/anaconda3/lib/python3.8/site-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.8/site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests>=2.31->yfinance) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests>=2.31->yfinance) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests>=2.31->yfinance) (2024.2.2)\n",
      "Downloading yfinance-0.2.40-py2.py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Building wheels for collected packages: frozendict, peewee\n",
      "  Building wheel for frozendict (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for frozendict: filename=frozendict-2.4.4-cp38-cp38-macosx_10_9_x86_64.whl size=37766 sha256=5cf681639db782e8a6b1a33c763f531a90b56e9757735c092583821952b68c29\n",
      "  Stored in directory: /Users/amayjain/Library/Caches/pip/wheels/7d/65/20/a8f7d1a2a99c9db2dfb0f83dddac9e847b02f45040768bf264\n",
      "  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peewee: filename=peewee-3.17.5-cp38-cp38-macosx_10_9_x86_64.whl size=272313 sha256=e0c48170c65b543b1120351ead979896324c852bfafac31e135891288399e68a\n",
      "  Stored in directory: /Users/amayjain/Library/Caches/pip/wheels/50/f5/5d/c6bc991ef2e027c2d14113be120f99704e268b48057a90529d\n",
      "Successfully built frozendict peewee\n",
      "Installing collected packages: peewee, multitasking, frozendict, yfinance\n",
      "Successfully installed frozendict-2.4.4 multitasking-0.0.11 peewee-3.17.5 yfinance-0.2.40\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-04-01</th>\n",
       "      <td>56.200001</td>\n",
       "      <td>56.471001</td>\n",
       "      <td>54.674500</td>\n",
       "      <td>55.105000</td>\n",
       "      <td>55.105000</td>\n",
       "      <td>51970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-02</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>56.138500</td>\n",
       "      <td>54.656502</td>\n",
       "      <td>55.851501</td>\n",
       "      <td>55.851501</td>\n",
       "      <td>56410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-03</th>\n",
       "      <td>55.735500</td>\n",
       "      <td>55.939499</td>\n",
       "      <td>53.754002</td>\n",
       "      <td>54.634998</td>\n",
       "      <td>54.634998</td>\n",
       "      <td>51374000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-06</th>\n",
       "      <td>56.650002</td>\n",
       "      <td>59.537498</td>\n",
       "      <td>56.250000</td>\n",
       "      <td>59.159500</td>\n",
       "      <td>59.159500</td>\n",
       "      <td>63320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-07</th>\n",
       "      <td>60.850498</td>\n",
       "      <td>61.039001</td>\n",
       "      <td>58.862499</td>\n",
       "      <td>59.127998</td>\n",
       "      <td>59.127998</td>\n",
       "      <td>61620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-27</th>\n",
       "      <td>104.620003</td>\n",
       "      <td>104.760002</td>\n",
       "      <td>101.930000</td>\n",
       "      <td>102.459999</td>\n",
       "      <td>102.459999</td>\n",
       "      <td>31120900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-28</th>\n",
       "      <td>102.440002</td>\n",
       "      <td>102.449997</td>\n",
       "      <td>99.739998</td>\n",
       "      <td>101.029999</td>\n",
       "      <td>101.029999</td>\n",
       "      <td>32057900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-29</th>\n",
       "      <td>102.279999</td>\n",
       "      <td>102.489998</td>\n",
       "      <td>100.650002</td>\n",
       "      <td>101.389999</td>\n",
       "      <td>101.389999</td>\n",
       "      <td>28779600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-30</th>\n",
       "      <td>100.910004</td>\n",
       "      <td>101.160004</td>\n",
       "      <td>99.779999</td>\n",
       "      <td>100.889999</td>\n",
       "      <td>100.889999</td>\n",
       "      <td>33086200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31</th>\n",
       "      <td>101.300003</td>\n",
       "      <td>103.889999</td>\n",
       "      <td>101.040001</td>\n",
       "      <td>103.730003</td>\n",
       "      <td>103.730003</td>\n",
       "      <td>36863400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>756 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Adj Close  \\\n",
       "Date                                                                     \n",
       "2020-04-01   56.200001   56.471001   54.674500   55.105000   55.105000   \n",
       "2020-04-02   55.000000   56.138500   54.656502   55.851501   55.851501   \n",
       "2020-04-03   55.735500   55.939499   53.754002   54.634998   54.634998   \n",
       "2020-04-06   56.650002   59.537498   56.250000   59.159500   59.159500   \n",
       "2020-04-07   60.850498   61.039001   58.862499   59.127998   59.127998   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2023-03-27  104.620003  104.760002  101.930000  102.459999  102.459999   \n",
       "2023-03-28  102.440002  102.449997   99.739998  101.029999  101.029999   \n",
       "2023-03-29  102.279999  102.489998  100.650002  101.389999  101.389999   \n",
       "2023-03-30  100.910004  101.160004   99.779999  100.889999  100.889999   \n",
       "2023-03-31  101.300003  103.889999  101.040001  103.730003  103.730003   \n",
       "\n",
       "              Volume  \n",
       "Date                  \n",
       "2020-04-01  51970000  \n",
       "2020-04-02  56410000  \n",
       "2020-04-03  51374000  \n",
       "2020-04-06  63320000  \n",
       "2020-04-07  61620000  \n",
       "...              ...  \n",
       "2023-03-27  31120900  \n",
       "2023-03-28  32057900  \n",
       "2023-03-29  28779600  \n",
       "2023-03-30  33086200  \n",
       "2023-03-31  36863400  \n",
       "\n",
       "[756 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the start and end date\n",
    "start_date = dt.datetime(2020, 4, 1)\n",
    "end_date = dt.datetime(2023, 4, 1)\n",
    " \n",
    "#loading from yahoo finance\n",
    "data = yf.download(\"GOOGL\", start_date, end_date)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's understand the meaning of each column.\n",
    "\n",
    "- Open = the price when the market opened in the morning.\n",
    "\n",
    "- High = the highest price during that trading day.\n",
    "\n",
    "- Low = the lowest price during that trading day.\n",
    "\n",
    "- Close = the price when the market closed in the afternoon.\n",
    "\n",
    "- Adj Close (Adjusted Close) = a price adjusted to make prices comparable over time.\n",
    "\n",
    "- Volume = number of shares of the stock traded that day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test Split\n",
    "\n",
    "We split data samples to training data points and test data points. We cannot randomly split training data points and test data points since time series data has timestamp and we can only use previous data to predict future data.\n",
    "\n",
    "We will use 80% data for training and 20% for testing. I only predict open price. You can also consider other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(604, 1) (152, 1)\n",
      "(604, 1)\n",
      "(152, 1)\n"
     ]
    }
   ],
   "source": [
    "# Setting 80 percent data for training\n",
    "training_data_len = int(len(data) * .8)\n",
    " \n",
    "# Splitting the dataset and selecting Open Price \n",
    "train_data = data[:training_data_len].iloc[:,:1] \n",
    "test_data = data[training_data_len:].iloc[:,:1]\n",
    "print(train_data.shape, test_data.shape)\n",
    "\n",
    "# change training data and test data to numpy array\n",
    "dataset_train = train_data.to_numpy()\n",
    "print(dataset_train.shape)\n",
    "\n",
    "dataset_test = test_data.to_numpy()\n",
    "print(dataset_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization\n",
    "\n",
    "Normalization is a crucial step in data preprocessing to enhance the effectiveness and interpretability of machine learning models.\n",
    "\n",
    "**Should we normalize the data before or after splitting it into training and testing sets?**\n",
    "\n",
    "We should split first and then normalize training data, then we use the \"same way\" to normalize test data. This recommendation is to prevent any information leakage from the testing set into the training set, which can lead to over-optimistic results and unrealistic performance evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a class for normalization\n",
    "\n",
    "class minmax():\n",
    "    \n",
    "    \"\"\"\n",
    "    minmax is a class of minmax normalizers.\n",
    "    Each normalizer has two instance attributes called min_val and max_val with default values 0 and 1, respectively.\n",
    "    They will be updated in fit_transform command.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, min_val = 0, max_val = 1):\n",
    "        \n",
    "        self.min_val = 0\n",
    "        self.max_val = 1\n",
    "        \n",
    "    def fit_transform(self, X):\n",
    "        \n",
    "        \"\"\"\n",
    "        X is supposed to be a 1D numpy array or 2D numpy array with only one row or one column.\n",
    "        This function returns normalized X which has the same shape of X.\n",
    "        The minimum value of X and the maximum value of X will replace self.min_val and self.max_val.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.min_val = np.min(X)\n",
    "        self.max_val = np.max(X)\n",
    "        \n",
    "        return (X - self.min_val) / (self.max_val - self.min_val)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X is supposed to be a 1D numpy array or 2D numpy array with only one row or one column.\n",
    "        This function returns normalized X which has the same shape of X.\n",
    "        \"\"\"\n",
    "        return (X - self.min_val) / (self.max_val - self.min_val)\n",
    "    \n",
    "    def inverse_transform(self, X_scaled):\n",
    "        \n",
    "        \"\"\"\n",
    "        X is supposed to be a 1D numpy array or 2D numpy array with only one row or one column.\n",
    "        This function takes normalized data as input and transforms it back to original scale.\n",
    "        The output has the same shape of X.\n",
    "        \"\"\"\n",
    "        \n",
    "        return X_scaled * (self.max_val - self.min_val) + self.min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = minmax()\n",
    "dataset_train = scalar.fit_transform(dataset_train)\n",
    "dataset_test = scalar.transform(dataset_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(604, 1)\n",
      "(152, 1)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_train.shape)\n",
    "print(dataset_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training samples and corresponding labels\n",
    "\n",
    "We should determine how many previous timestamps are used to predict the future labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_set(data, window_sizeb=b20):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function takes data, which is a 2D numpy array and window_size, which is an integer as inputs.\n",
    "    window_size represents the number of timestamps included in each sample. The default value is 20.\n",
    "    Function should return two lists. One contains samples, the other contains labels. \n",
    "    \"\"\"\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(window_size, len(data)):\n",
    "        X.append(data[i-window_size:i,0])\n",
    "        y.append(data[i,0])\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (584, 20, 1) y_train : (584, 1)\n",
      "X_test : (132, 20, 1) y_test : (132, 1)\n"
     ]
    }
   ],
   "source": [
    "timestamp = 20\n",
    "\n",
    "# create training and test data set\n",
    "X_train, y_train = data_set(dataset_train, timestamp)\n",
    "X_test, y_test = data_set(dataset_test, timestamp)\n",
    "\n",
    "# The data is converted to Numpy array\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "#Reshaping\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1],1))\n",
    "y_train = y_train.reshape((y_train.shape[0],1))\n",
    "print(\"X_train :\",X_train.shape,\"y_train :\",y_train.shape)\n",
    "\n",
    "# The data is converted to numpy array\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    " \n",
    "#Reshaping\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1],1))\n",
    "y_test = y_test.reshape((y_test.shape[0],1))\n",
    "print(\"X_test :\",X_test.shape,\"y_test :\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network\n",
    "\n",
    "Recurrent neural network is designed to use sequential data or time series data. These deep learning algorithms are commonly used for ordinal or temporal problems, such as language translation, natural language processing (nlp), speech recognition, and image captioning; they are incorporated into popular applications such as Siri, voice search, and Google Translate.\n",
    "\n",
    "Here is the recurrent structure:\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n",
    "Image from *Wikipedia*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN operation:\n",
    "\n",
    "I would like to use the following code to explain the structure of recurrent neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.02630292]\n",
      "  [0.07890877]\n",
      "  [0.15781754]]]\n"
     ]
    }
   ],
   "source": [
    "# Construct a Simple RNN model:\n",
    "test_model = tf.keras.models.Sequential(\n",
    "    [\n",
    "\n",
    "    # input shape\n",
    "        # 3 refers to using previous 3 days for predicting\n",
    "        # 1 refers to one nueron input (1 feature)\n",
    "    # output shape\n",
    "        # 1 output neuron\n",
    "    tf.keras.layers.SimpleRNN(1, use_bias = False, return_sequences = True, activation = \"linear\", input_shape = (3, 1))\n",
    "    \n",
    "    ]\n",
    ")\n",
    "data = np.array([0.1, 0.2, 0.3]).reshape((1, 3, 1))\n",
    "# make and show prediction\n",
    "print(test_model.predict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.26302922]], dtype=float32), array([[1.]], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RNN\n",
    "\n",
    "The second model is simple RNN model. Instead of using dense layer/fully connected layer, I use simple recurrent layer to construct neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `tf.keras.layers.RNN` to build a simple recurrence layer.\n",
    "\n",
    "    tf.keras.layers.SimpleRNN(\n",
    "        units,\n",
    "        activation='tanh',\n",
    "        use_bias=True,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        recurrent_initializer='orthogonal',\n",
    "        bias_initializer='zeros',\n",
    "        kernel_regularizer=None,\n",
    "        recurrent_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        activity_regularizer=None,\n",
    "        kernel_constraint=None,\n",
    "        recurrent_constraint=None,\n",
    "        bias_constraint=None,\n",
    "        dropout=0.0,\n",
    "        recurrent_dropout=0.0,\n",
    "        return_sequences=False,\n",
    "        return_state=False,\n",
    "        go_backwards=False,\n",
    "        stateful=False,\n",
    "        unroll=False,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "You should be familiar with some arguments, but I want to highlight `input_shape` and `return_sequence`:\n",
    "\n",
    "- Input shape = [sequence length, number of values per timestamp]. sequence length <==> timestamp\n",
    "\n",
    "- That return sequences return the hidden state output for each input time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "292/292 [==============================] - 2s 5ms/step - loss: 0.0084 - mse: 0.0084\n",
      "Epoch 2/10\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0030 - mse: 0.0030\n",
      "Epoch 3/10\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0024 - mse: 0.0024\n",
      "Epoch 4/10\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 5/10\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0016 - mse: 0.0016\n",
      "Epoch 6/10\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0017 - mse: 0.0017\n",
      "Epoch 7/10\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0015 - mse: 0.0015\n",
      "Epoch 8/10\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 9/10\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 10/10\n",
      "292/292 [==============================] - 1s 5ms/step - loss: 0.0013 - mse: 0.0013\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd421073ed0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initializing the RNN\n",
    "RNN = tf.keras.models.Sequential([\n",
    "    \n",
    "    tf.keras.layers.SimpleRNN(units = 50, \n",
    "                        activation = \"tanh\",\n",
    "                        return_sequences = True,\n",
    "                        input_shape = (X_train.shape[1],1)),      # X_train.shape[1] <==> window_size\n",
    "    \n",
    "    tf.keras.layers.SimpleRNN(units = 50, \n",
    "                        activation = \"tanh\",\n",
    "                        return_sequences = True),\n",
    "    \n",
    "    tf.keras.layers.SimpleRNN(units = 50),\n",
    "    \n",
    "    tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    " \n",
    "# compiling RNN\n",
    "\n",
    "RNN.compile(optimizer = \"adam\",\n",
    "                  loss = \"mean_squared_error\",\n",
    "             metrics=[\"mse\"])\n",
    " \n",
    "# fitting the model\n",
    "RNN.fit(X_train, y_train, epochs = 10, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 8.4524e-04 - mse: 8.4524e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0008452351321466267, 0.0008452351321466267]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008452351856225926"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_pred = RNN.predict(X_test)\n",
    "np.mean((RNN_pred-y_test)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5022462 ],\n",
       "       [0.4708758 ],\n",
       "       [0.47630224],\n",
       "       [0.4629405 ],\n",
       "       [0.47237012],\n",
       "       [0.4623012 ],\n",
       "       [0.46561924],\n",
       "       [0.45527095],\n",
       "       [0.45067656],\n",
       "       [0.4841776 ],\n",
       "       [0.4847445 ],\n",
       "       [0.4836507 ],\n",
       "       [0.4745545 ],\n",
       "       [0.4663127 ],\n",
       "       [0.4518789 ],\n",
       "       [0.453041  ],\n",
       "       [0.4353574 ],\n",
       "       [0.47743762],\n",
       "       [0.4801193 ],\n",
       "       [0.5138572 ],\n",
       "       [0.48504168],\n",
       "       [0.47212267],\n",
       "       [0.45053437],\n",
       "       [0.49378166],\n",
       "       [0.5171776 ],\n",
       "       [0.45691156],\n",
       "       [0.42185187],\n",
       "       [0.4004987 ],\n",
       "       [0.43762574],\n",
       "       [0.45000675],\n",
       "       [0.40037885],\n",
       "       [0.34336698],\n",
       "       [0.3349581 ],\n",
       "       [0.3646732 ],\n",
       "       [0.3879885 ],\n",
       "       [0.3763853 ],\n",
       "       [0.39778054],\n",
       "       [0.42402887],\n",
       "       [0.43819153],\n",
       "       [0.45731908],\n",
       "       [0.45208922],\n",
       "       [0.43595102],\n",
       "       [0.45887703],\n",
       "       [0.46318713],\n",
       "       [0.44506022],\n",
       "       [0.45318037],\n",
       "       [0.46469653],\n",
       "       [0.45496646],\n",
       "       [0.4391362 ],\n",
       "       [0.4271578 ],\n",
       "       [0.48910385],\n",
       "       [0.4874577 ],\n",
       "       [0.47885963],\n",
       "       [0.47351724],\n",
       "       [0.44384384],\n",
       "       [0.43277723],\n",
       "       [0.4249907 ],\n",
       "       [0.41065   ],\n",
       "       [0.45779762],\n",
       "       [0.44973522],\n",
       "       [0.41595656],\n",
       "       [0.38480538],\n",
       "       [0.3803273 ],\n",
       "       [0.3675175 ],\n",
       "       [0.3784926 ],\n",
       "       [0.37159058],\n",
       "       [0.35719767],\n",
       "       [0.3758167 ],\n",
       "       [0.3573609 ],\n",
       "       [0.34708115],\n",
       "       [0.34733784],\n",
       "       [0.36969173],\n",
       "       [0.38753885],\n",
       "       [0.3594921 ],\n",
       "       [0.3436851 ],\n",
       "       [0.36110735],\n",
       "       [0.34424058],\n",
       "       [0.36913517],\n",
       "       [0.39644933],\n",
       "       [0.3911754 ],\n",
       "       [0.39783484],\n",
       "       [0.40368056],\n",
       "       [0.3856805 ],\n",
       "       [0.42446405],\n",
       "       [0.46653032],\n",
       "       [0.47013277],\n",
       "       [0.4416055 ],\n",
       "       [0.43948847],\n",
       "       [0.45432097],\n",
       "       [0.4615594 ],\n",
       "       [0.451932  ],\n",
       "       [0.46862006],\n",
       "       [0.54197437],\n",
       "       [0.52630997],\n",
       "       [0.5085906 ],\n",
       "       [0.50032604],\n",
       "       [0.49311453],\n",
       "       [0.48414174],\n",
       "       [0.44253698],\n",
       "       [0.42740723],\n",
       "       [0.4324995 ],\n",
       "       [0.44026637],\n",
       "       [0.4443146 ],\n",
       "       [0.43305233],\n",
       "       [0.41139296],\n",
       "       [0.39672568],\n",
       "       [0.40261066],\n",
       "       [0.38236895],\n",
       "       [0.38354033],\n",
       "       [0.3828438 ],\n",
       "       [0.382631  ],\n",
       "       [0.38278845],\n",
       "       [0.40393767],\n",
       "       [0.4189746 ],\n",
       "       [0.42572555],\n",
       "       [0.41573137],\n",
       "       [0.41465622],\n",
       "       [0.40054327],\n",
       "       [0.3821974 ],\n",
       "       [0.40605685],\n",
       "       [0.41992414],\n",
       "       [0.44650814],\n",
       "       [0.48820806],\n",
       "       [0.4868726 ],\n",
       "       [0.48557517],\n",
       "       [0.51467454],\n",
       "       [0.5300416 ],\n",
       "       [0.5334634 ],\n",
       "       [0.53004044],\n",
       "       [0.5095279 ],\n",
       "       [0.505659  ],\n",
       "       [0.4953094 ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_1 (SimpleRNN)     (None, 20, 50)            2600      \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 20, 50)            5050      \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 12,751\n",
      "Trainable params: 12,751\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "RNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advantages of RNNs:\n",
    "\n",
    "- Handle sequential data effectively, including text, speech, and time series.\n",
    "- Process inputs of any length, unlike feedforward neural networks.\n",
    "- Share weights across time steps, enhancing training efficiency.\n",
    "\n",
    "#### Disadvantages of RNNs:\n",
    "\n",
    "- Prone to vanishing and exploding gradient problems, hindering learning.\n",
    "- Training can be challenging, especially for long sequences.\n",
    "- Computationally slower than other neural network architectures.\n",
    "\n",
    "For more details, please look at a short overview: https://www.analyticsvidhya.com/blog/2022/03/a-brief-overview-of-recurrent-neural-networks-rnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Long Short-term Memory\n",
    "\n",
    "Long short-term memory (LSTM) network is a recurrent neural network (RNN), aimed to deal with the vanishing gradient problem present in traditional RNNs. However, it still suffers exploding gradient problem.\n",
    "\n",
    "The intuition behind the LSTM architecture is to create an additional module in a neural network that learns when to remember and when to forget pertinent information. In other words, the network effectively learns which information might be needed later on in a sequence and when that information is no longer needed.\n",
    "\n",
    "LSTM architecture:\n",
    "\n",
    "![](https://dezyre.gumlet.io/images/blog/lstm-model/The_Architecture_of_the_LSTM_Model.png?w=940&dpr=2.0)\n",
    "\n",
    "*Image from Projectpro*\n",
    "\n",
    "\n",
    "For more details, please check this [page](https://www.projectpro.io/article/lstm-model/832).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build LSTM layer, we use command\n",
    "\n",
    "    tf.keras.layers.LSTM(\n",
    "        units,\n",
    "        activation='tanh',\n",
    "        recurrent_activation='sigmoid',\n",
    "        use_bias=True,\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        recurrent_initializer='orthogonal',\n",
    "        bias_initializer='zeros',\n",
    "        unit_forget_bias=True,\n",
    "        kernel_regularizer=None,\n",
    "        recurrent_regularizer=None,\n",
    "        bias_regularizer=None,\n",
    "        activity_regularizer=None,\n",
    "        kernel_constraint=None,\n",
    "        recurrent_constraint=None,\n",
    "        bias_constraint=None,\n",
    "        dropout=0.0,\n",
    "        recurrent_dropout=0.0,\n",
    "        return_sequences=False,\n",
    "        return_state=False,\n",
    "        go_backwards=False,\n",
    "        stateful=False,\n",
    "        time_major=False,\n",
    "        unroll=False,\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "584/584 [==============================] - 4s 5ms/step - loss: 0.0075 - mse: 0.0075\n",
      "Epoch 2/10\n",
      "584/584 [==============================] - 3s 5ms/step - loss: 0.0023 - mse: 0.0023\n",
      "Epoch 3/10\n",
      "584/584 [==============================] - 3s 5ms/step - loss: 0.0020 - mse: 0.0020\n",
      "Epoch 4/10\n",
      "584/584 [==============================] - 3s 5ms/step - loss: 0.0019 - mse: 0.0019\n",
      "Epoch 5/10\n",
      "584/584 [==============================] - 3s 5ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 6/10\n",
      "584/584 [==============================] - 3s 5ms/step - loss: 0.0014 - mse: 0.0014\n",
      "Epoch 7/10\n",
      "584/584 [==============================] - 3s 5ms/step - loss: 0.0010 - mse: 0.0010   \n",
      "Epoch 8/10\n",
      "584/584 [==============================] - 3s 5ms/step - loss: 0.0011 - mse: 0.0011\n",
      "Epoch 9/10\n",
      "584/584 [==============================] - 3s 5ms/step - loss: 9.6848e-04 - mse: 9.6848e-04\n",
      "Epoch 10/10\n",
      "584/584 [==============================] - 4s 6ms/step - loss: 9.4864e-04 - mse: 9.4864e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd440efdf10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model = tf.keras.models.Sequential([\n",
    "    \n",
    "    tf.keras.layers.LSTM(50, return_sequences=True, input_shape = (X_train.shape[1],1)),\n",
    "    \n",
    "    tf.keras.layers.LSTM(50),\n",
    "    \n",
    "    tf.keras.layers.Dense(1)  \n",
    "])\n",
    "\n",
    "LSTM_model.compile(optimizer='adam', loss='mean_squared_error', metrics=[\"mse\"])\n",
    "LSTM_model.fit(X_train, y_train, epochs = 10, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 6.1648e-04 - mse: 6.1648e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0006164803053252399, 0.0006164803053252399]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0006164802820332385"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_pred = LSTM_model.predict(X_test)\n",
    "np.mean((LSTM_pred-y_test)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49551788],\n",
       "       [0.47383136],\n",
       "       [0.47106907],\n",
       "       [0.4603982 ],\n",
       "       [0.46566522],\n",
       "       [0.45569837],\n",
       "       [0.45794734],\n",
       "       [0.4480574 ],\n",
       "       [0.44154757],\n",
       "       [0.46522644],\n",
       "       [0.4710193 ],\n",
       "       [0.47711247],\n",
       "       [0.47253385],\n",
       "       [0.46379295],\n",
       "       [0.44948092],\n",
       "       [0.44369283],\n",
       "       [0.4278626 ],\n",
       "       [0.45581254],\n",
       "       [0.4610589 ],\n",
       "       [0.49136016],\n",
       "       [0.48005375],\n",
       "       [0.4725893 ],\n",
       "       [0.45489395],\n",
       "       [0.47673362],\n",
       "       [0.49530515],\n",
       "       [0.4546    ],\n",
       "       [0.4241311 ],\n",
       "       [0.39981145],\n",
       "       [0.41389236],\n",
       "       [0.42281565],\n",
       "       [0.39521018],\n",
       "       [0.35226882],\n",
       "       [0.32929987],\n",
       "       [0.3337131 ],\n",
       "       [0.34827387],\n",
       "       [0.35197324],\n",
       "       [0.37625903],\n",
       "       [0.4028419 ],\n",
       "       [0.41477808],\n",
       "       [0.43838823],\n",
       "       [0.444408  ],\n",
       "       [0.4379512 ],\n",
       "       [0.44709823],\n",
       "       [0.4413849 ],\n",
       "       [0.42947638],\n",
       "       [0.43341205],\n",
       "       [0.44469517],\n",
       "       [0.44128308],\n",
       "       [0.43010762],\n",
       "       [0.41961968],\n",
       "       [0.45938268],\n",
       "       [0.46353695],\n",
       "       [0.46430588],\n",
       "       [0.46309602],\n",
       "       [0.4420649 ],\n",
       "       [0.42669654],\n",
       "       [0.4113564 ],\n",
       "       [0.39951104],\n",
       "       [0.43036857],\n",
       "       [0.427488  ],\n",
       "       [0.40944925],\n",
       "       [0.38566273],\n",
       "       [0.37330103],\n",
       "       [0.35591286],\n",
       "       [0.35538763],\n",
       "       [0.3507747 ],\n",
       "       [0.34191555],\n",
       "       [0.34846345],\n",
       "       [0.3405451 ],\n",
       "       [0.33356968],\n",
       "       [0.33268967],\n",
       "       [0.34907833],\n",
       "       [0.3618554 ],\n",
       "       [0.34770775],\n",
       "       [0.33515036],\n",
       "       [0.33997682],\n",
       "       [0.32864124],\n",
       "       [0.34289777],\n",
       "       [0.36571047],\n",
       "       [0.37134513],\n",
       "       [0.3794767 ],\n",
       "       [0.38292757],\n",
       "       [0.37432784],\n",
       "       [0.39901546],\n",
       "       [0.43075377],\n",
       "       [0.44388464],\n",
       "       [0.4289399 ],\n",
       "       [0.4277341 ],\n",
       "       [0.434309  ],\n",
       "       [0.438983  ],\n",
       "       [0.43666628],\n",
       "       [0.4484839 ],\n",
       "       [0.5046951 ],\n",
       "       [0.5058205 ],\n",
       "       [0.49730092],\n",
       "       [0.49949232],\n",
       "       [0.49269354],\n",
       "       [0.4756748 ],\n",
       "       [0.438148  ],\n",
       "       [0.4206891 ],\n",
       "       [0.41511515],\n",
       "       [0.41536248],\n",
       "       [0.4222718 ],\n",
       "       [0.4215321 ],\n",
       "       [0.4076477 ],\n",
       "       [0.3925134 ],\n",
       "       [0.38812092],\n",
       "       [0.37098488],\n",
       "       [0.36634654],\n",
       "       [0.36200976],\n",
       "       [0.36448592],\n",
       "       [0.36370054],\n",
       "       [0.3811007 ],\n",
       "       [0.39915335],\n",
       "       [0.4118636 ],\n",
       "       [0.40950972],\n",
       "       [0.40637162],\n",
       "       [0.3923922 ],\n",
       "       [0.3729721 ],\n",
       "       [0.3819866 ],\n",
       "       [0.39264706],\n",
       "       [0.41714293],\n",
       "       [0.45523623],\n",
       "       [0.4682581 ],\n",
       "       [0.47769296],\n",
       "       [0.50163364],\n",
       "       [0.5159531 ],\n",
       "       [0.518935  ],\n",
       "       [0.5162575 ],\n",
       "       [0.49937093],\n",
       "       [0.49292684],\n",
       "       [0.4827927 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 20, 50)            10400     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 30,651\n",
      "Trainable params: 30,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "LSTM_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "I want to draw three curves in one single plot which contains true time series data, predictions obtained from simple RNN and LSTM.\n",
    "\n",
    "We first need to transform predcitions back to original scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inverse minmax transform:\n",
    "\n",
    "# true training and test time series data\n",
    "true_train = scalar.inverse_transform(y_train)\n",
    "true_test = scalar.inverse_transform(y_test)\n",
    "true = np.vstack((true_train,true_test))\n",
    "\n",
    "# prediction obtained from RNN and LSTM\n",
    "RNN_vis = scalar.inverse_transform(RNN_pred)\n",
    "LSTM_vis = scalar.inverse_transform(LSTM_pred)\n",
    "\n",
    "# parameters for plotting:\n",
    "m_train = np.size(true_train)\n",
    "m_test = np.size(true_test)\n",
    "\n",
    "# visualization\n",
    "plt.plot(range(m_train+m_test), true, 'b-', label='true value')\n",
    "plt.plot(range(m_train, m_train+m_test), RNN_vis, label='RNN')\n",
    "plt.plot(range(m_train, m_train+m_test), LSTM_vis, label='LSTM')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
